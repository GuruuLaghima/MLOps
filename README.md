
## **Pr√©sentation du projet**

Ce projet a pour objectif de d√©ployer une cha√Æne compl√®te **MLOps** en int√©grant les pratiques **DevOps** pour le d√©ploiement et le suivi d'un mod√®le de Machine Learning. L'architecture repose sur des outils modernes permettant l'automatisation, la versioning et le monitoring des mod√®les ML. Voici les principaux composants du projet :

1. **Infrastructure as Code (IaC)** avec **Terraform** pour provisionner les ressources cloud (AWS EC2).
2. **Configuration automatis√©e** des serveurs avec **Ansible** pour l'installation des outils n√©cessaires (Docker, Grafana, Prometheus).
3. **Containerisation** de l'application ML avec **Docker** pour garantir un d√©ploiement portable et reproductible.
4. **CI/CD** avec **GitHub Actions** pour automatiser les tests, la construction des images Docker et le d√©ploiement sur EC2.
5. **Monitoring** avec **Prometheus** pour la collecte des m√©triques et **Grafana** pour la visualisation.

L'application propose une **API Flask** qui permet d'effectuer des pr√©dictions via un mod√®le de Machine Learning entra√Æn√© avec **XGBoost**.

---


## **1. Infrastructure**

### **1.1. Pr√©paration de la cl√© `.pem` pour SSH**

Avant toute chose, une cl√© SSH est n√©cessaire pour se connecter √† l'instance EC2. Voici comment la cr√©er :

1. **G√©n√©rer une paire de cl√©s avec `ssh-keygen`** :
   ```bash
   ssh-keygen -t rsa -b 4096 -f ~/.ssh/myKey.pem
   ```

2. **Rendre la cl√© priv√©e utilisable** :
   ```bash
   chmod 400 ~/.ssh/myKey.pem
   ```

3. **Ajouter la cl√© dans Terraform** :
   - Lors de la configuration de Terraform, sp√©cifie la cl√© publique dans les param√®tres EC2.

4. **Connexion SSH √† l'instance** (plus tard) :
   ```bash
   ssh -i ~/.ssh/myKey.pem ec2-user@<PUBLIC_IP>
   ```
   Remplacez `<PUBLIC_IP>` par l‚Äôadresse IPv4 publique de l'instance.

---

### **1.2. Explication des outils : Terraform & Ansible**

- **Terraform** : Utilis√© pour **provisionner l'infrastructure** ( instances EC2 sur AWS).  
   *Il permet de d√©crire l'infrastructure comme du code (IaC), facilitant la reproductibilit√© et l'automatisation.*  

- **Ansible** : Une fois l'infrastructure d√©ploy√©e, Ansible est utilis√© pour **configurer les serveurs** (installer Docker, Grafana, Prometheus, etc.).  
   *Il ex√©cute des "playbooks" contenant des t√¢ches automatis√©es.*

---

### **1.3. Mise en place de l'infrastructure cloud via Terraform**

1. **Initialise Terraform** dans le r√©pertoire `terraform` :
   ```bash
   cd terraform
   terraform init
   ```

2. **Planifie les modifications** :
   ```bash
   terraform plan
   ```

3. **D√©ploie l'infrastructure** :
   ```bash
   terraform apply
   ```
   - Confirme avec `yes`.

4. **R√©cup√®re l'IP de l'instance (Public IPv4 address)** :
   ```bash
   terraform output
   ```

---

### **1.4. Configuration des serveurs via Ansible**

1. **Configure le fichier `hosts.ini`** dans `ansible/` :
   ```ini
   [docker_host]
   <PUBLIC_IP> ansible_user=ec2-user ansible_ssh_private_key_file=~/.ssh/myKey.pem
   ```

2. **Ex√©cute le playbook Ansible pour installer Docker** :
   ```bash
   cd ansible
   ansible-playbook -i hosts.ini playbooks/setup_docker.yml
   ```

3. **V√©rifie l'installation de Docker** :
   ```bash
   ssh -i ~/.ssh/myKey.pem ec2-user@<instance_ip>
   docker --version
   ```

---

### **1.5. Architecture containeris√©e avec Docker**

1. **Lancement des services Docker** :  
   Le fichier `docker-compose.yml` configure les services :
   - **Prometheus** (Service de collecte des m√©triques via `monitoring/prometheus/prometheus.yml`.)
   - **Grafana** (Plateforme de visualisation des m√©triques.)
   - **API ML** (API pour effectuer des pr√©dictions √† partir d'un mod√®le XGBoost.)

   Ex√©cutez :
   ```bash
   cd docker
   docker-compose up -d
   ```


---

### **1.6. Test des services (post-d√©ploiement)**

Pour v√©rifier que tout fonctionne correctement **apr√®s le d√©ploiement de l'API** :

- **Tester l'API depuis l'instance** :

	Pull l'image Docker :
	```bash
	docker pull wiltch/xgboost-ml-api:latest
	```
	Run le container :
	```bash
	docker run -d -p 5001:5001 wiltch/xgboost-ml-api:latest
	```
	
   ```bash
   curl -X POST -H "Content-Type: application/json" \
   -d '{"features": [[8.3252, 41, 6.9841, 1.023810, 322, 2.5556, 37.88, -122.23]]}' \
   http://127.0.0.1:5001/predict
   ```

- **Tester l'API depuis le poste local** (HTTPS avec IP publique) :
   ```bash
   curl -k -X POST -H "Content-Type: application/json" \
   -d '{"features": [[8.3252, 41, 6.9841, 1.023810, 322, 2.5556, 37.88, -122.23]]}' \
   https://<instance_ip>/predict
   ```

- **Acc√©der aux interfaces Prometheus et Grafana** :
   - **Prometheus** : `http://<PUBLIC_IP>:9090`
   - **Grafana** : `http://<PUBLIC_IP>:3000`
   - Identifiants : `admin` / `admin`

---



### **2. Application ML**

Mise en place d'une **API ML** bas√©e sur un mod√®le XGBoost et d'assurer le **versioning des mod√®les** avec **MLflow**. 

---

### **2.1 Entra√Ænement du mod√®le avec MLflow**

1. **Description** :
   - Le mod√®le **XGBoost** est entra√Æn√© √† partir d'un jeu de donn√©es pour effectuer des pr√©dictions.
   - **MLflow** est utilis√© pour le **suivi des exp√©riences** et la **version des mod√®les**.

2. **Structure du projet** :
   Le code source de cette partie se trouve dans le dossier `ml/model/`.

   - `train_model.py` : Script d'entra√Ænement du mod√®le.
   - `model.pkl` : Mod√®le entra√Æn√©, sauvegard√© au format `.pkl` pour l'API.

3. **Ex√©cution du script d'entra√Ænement** :

   ```bash
   cd ml/model
   python train_model.py
   ```

   - Ce script :
     - Entra√Æne le mod√®le XGBoost.
     - Log les m√©triques (comme la RMSE) et sauvegarde le mod√®le avec MLflow.
   - Une fois termin√©, un dossier `mlruns` est cr√©√© pour stocker les artefacts et les versions du mod√®le.

4. **D√©marrage de l'interface MLflow** :

   Depuis le dossier `ml`, lancez MLflow pour voir les r√©sultats et les mod√®les :

   ```bash
   mlflow ui
   ```
   <img width="732" alt="image" src="https://github.com/user-attachments/assets/bc8245c9-a6e0-4ca2-9d7d-72ac5dd90fe8" />


   Acc√©dez √† l'interface sur `http://127.0.0.1:5000` pour voir :
   - Les **exp√©riences** enregistr√©es.
   - Les **mod√®les sauvegard√©s**.
   - Les m√©triques comme la RMSE.
<img width="1172" alt="image" src="https://github.com/user-attachments/assets/ff4333da-d5c0-475b-9ade-460fff4be988" />

---

### **2.2 D√©ploiement de l'API ML**

1. **Description** :
   - Une **API Flask** est cr√©√©e pour servir le mod√®le ML.
   - L'API prend en entr√©e des **features** JSON et renvoie les **pr√©dictions**.

2. **Structure du projet** :
   - **Code source** : `ml/api/app.py`
   - **D√©pendances** : `ml/api/requirements.txt`
   - **Dockerfile** : Permet de containeriser l'API.

3. **Test de l'API en local** :

   Depuis le dossier `ml/api`, testez l'API :

   ```bash
   cd ml/api
   python app.py
   ```

   **Test des pr√©dictions** avec `curl` :

   ```bash
   curl -X POST -H "Content-Type: application/json" \
   -d '{"features": [[8.3252, 41, 6.9841, 1.023810, 322, 2.5556, 37.88, -122.23]]}' \
   http://127.0.0.1:5001/predict
   ```

---


### **2.3 Versioning avec MLflow**

Une fois le mod√®le d√©ploy√© et l'API fonctionnelle :

1. **V√©rifiez les versions du mod√®le** :
   - Rendez-vous dans l'interface **MLflow UI** (`http://127.0.0.1:5000`) pour voir :
     - Les versions des mod√®les.
     - Les artefacts sauvegard√©s.
     - Les m√©triques d'entra√Ænement.



---



### **4. Monitoring avec Prometheus et Grafana**

---

### **4.1. Objectif du monitoring**

Le monitoring permet de suivre les **performances de l'infrastructure** et de l'API ML :  
- **Prometheus** collecte et stocke les m√©triques.  
- **Grafana** permet de **visualiser les m√©triques** via des tableaux de bord interactifs.

---

### **4.2. Copie des fichiers de configuration dans l'instance**

1. **Copiez les fichiers de monitoring sur l'instance EC2** :
   Depuis votre poste local, ex√©cutez :
   ```bash
   rsync -av --exclude=".DS_Store" -e "ssh -i ~/.ssh/myKey.pem" monitoring ec2-user@<PUBLIC_IP>:/home/ec2-user/
   ```

2. **Structure des dossiers apr√®s la copie** :
   - `/home/ec2-user/monitoring/prometheus/prometheus.yml`
   - `/home/ec2-user/monitoring/grafana/{datasources.yml}`

3. **Assurez-vous que les permissions sont correctes pour Grafana** :
   ```bash
   sudo chown -R 472:472 /home/ec2-user/monitoring/grafana
   ```

---

### **4.3. Configuration de Prometheus**

1. **Fichier `prometheus.yml`**  
   Le fichier de configuration se trouve dans `monitoring/prometheus/prometheus.yml` :
   ```yaml
   global:
     scrape_interval: 15s

   scrape_configs:
     - job_name: 'xgboost-api'
       static_configs:
         - targets: ['xgboost-api:5001']
   ```

   - **`scrape_interval`** : Intervalle pour collecter les m√©triques.  
   - **`targets`** : URL de l'API exposant les m√©triques via `/metrics`.

---

### **4.4. Configuration de Grafana**

1. **Volume pour persister les donn√©es Grafana** :  
   Le fichier `docker-compose.yml` dans `docker/` monte un volume pour sauvegarder les donn√©es :
   ```yaml
   grafana:
     image: grafana/grafana
     container_name: grafana
     ports:
       - "3000:3000"
     restart: always
     environment:
       - GF_SECURITY_ADMIN_USER=admin
       - GF_SECURITY_ADMIN_PASSWORD=admin
     volumes:
       - ../monitoring/grafana:/var/lib/grafana
   ```

2. **Configuration de la source de donn√©es** :
   - Le fichier `datasources.yml` est copi√© dans `monitoring/grafana/` :
   ```yaml
   apiVersion: 1
   datasources:
     - name: Prometheus
       type: prometheus
       access: proxy
       url: http://prometheus:9090
       isDefault: true
   ```

---

### **4.5. D√©marrage des services de monitoring**

1. **Assurez-vous d'√™tre dans le r√©pertoire Docker** :
   ```bash
   cd docker
   ```

2. **Relancez Docker Compose** pour d√©ployer Prometheus et Grafana :
   ```bash
   docker-compose down
   docker-compose up -d
   ```

3. **V√©rifiez l'√©tat des conteneurs** :
   ```bash
   docker ps
   ```

   Vous devriez voir les conteneurs suivants en cours d'ex√©cution :
   - **prometheus** (port `9090`)
   - **grafana** (port `3000`)
   - **xgboost-api** (port `5001`)

---

### **4.6. Configuration de Grafana**

1. **Acc√©dez √† Grafana** :  
   URL : `http://<PUBLIC_IP>:3000`  
   Identifiants par d√©faut :  
   - **Utilisateur** : `admin`  
   - **Mot de passe** : `admin`

2. **Ajout de Prometheus comme source de donn√©es** :
   - Allez dans **Configuration > Data Sources > Add data source**.
   - Choisissez **Prometheus**.
   - Configurez l'URL suivante :  
     ```
     http://prometheus:9090
     ```
   - Cliquez sur **Save & Test** pour valider.

---

### **4.7. Visualisation des m√©triques dans Grafana**

1. **Importation d‚Äôun tableau de bord existant** :
   - Allez dans **Dashboards > Import**.
   - Utilisez un tableau de bord pr√©d√©fini depuis [Grafana Dashboards](https://grafana.com/grafana/dashboards/).  
   - Exemple : **ID 1860** (Node Exporter Full).
  
     <img width="610" alt="image" src="https://github.com/user-attachments/assets/6a3af744-f4e8-4855-a080-1dfbc27591c6" />


2. **Cr√©ation de graphiques personnalis√©s** :
   - Acc√©dez √† **Dashboards > New Panel**.
   - Utilisez des requ√™tes PromQL pour afficher les m√©triques :  
     - **Nombre total de requ√™tes de pr√©diction** :  
       ```promql
       prediction_requests_total
       ```  
     - **Nombre d'erreurs de pr√©diction** :  
       ```promql
       prediction_errors_total
       ```  
     - **M√©triques li√©es au garbage collector Python** :  
       ```promql
       python_gc_collections_total
       ```

---

### **4.8. V√©rification finale**

1. **Prometheus** :
   - Allez sur :  
     ```
     http://<PUBLIC_IP>:9090
     ```
   - V√©rifiez que le job **`xgboost-api`** appara√Æt dans **Status > Targets**.  
<img width="1435" alt="image" src="https://github.com/user-attachments/assets/458a93ec-2725-4ade-8a1c-96fdf420a300" />


2. **Grafana** :
   - V√©rifiez que les **tableaux de bord** affichent correctement les m√©triques collect√©es par Prometheus.

---



### **üöë D√©pannage : Probl√®mes de ports üîß**

Si l'acc√®s √† certains services est bloqu√© (par exemple, Grafana, Prometheus ou l'API) üö´ :

1. **üîç V√©rifiez les r√®gles de s√©curit√©** configur√©es dans Terraform pour les ports requis.  

   - Exemple pour ouvrir le port **5001** utilis√© par l'API üõ†Ô∏è :

   ```hcl
   ingress {
     from_port   = 5001
     to_port     = 5001
     protocol    = "tcp"
     cidr_blocks = ["0.0.0.0/0"]
   }
   ```

2. **üñ•Ô∏è Modifiez les r√®gles directement dans la console AWS** :  
   - Allez dans **EC2 > Security Groups** üìã.  
   - S√©lectionnez le groupe de s√©curit√© attach√© √† votre instance üåê.  
   - Ajoutez une r√®gle pour autoriser le port sp√©cifique (exemple : TCP/5001, source : `0.0.0.0/0`) ‚úÖ.

3. **üöÄ Red√©ployez les modifications avec Terraform** pour appliquer les nouvelles r√®gles :  
   ```bash
   cd terraform
   terraform apply
   ```

4. **üîÑ Red√©marrez les services concern√©s** si n√©cessaire :  
   ```bash
   docker-compose restart
   ```

5. **üß™ Testez l'acc√®s aux services** :  
   - **üöÄ API** : `https://<PUBLIC_IP>:5001/predict`  
   - **üìä Grafana** : `http://<PUBLIC_IP>:3000`  
   - **üìà Prometheus** : `http://<PUBLIC_IP>:9090`  

üéâ **Votre acc√®s devrait maintenant fonctionner !** Si le probl√®me persiste, v√©rifiez les logs des services pour identifier d'autres erreurs. üõ°Ô∏è

---
